{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-18T23:40:39.020405Z",
     "start_time": "2024-12-18T23:40:35.869638Z"
    }
   },
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "import nltk\n",
    "import os\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('punkt')  # Word tokenizer\n",
    "nltk.download('stopwords')  # Stopwords list for multiple languages"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T21:17:30.672399Z",
     "start_time": "2024-12-18T21:17:30.652242Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define a preprocessing function for Russian\n",
    "def preprocess_russian_text(text):\n",
    "    \"\"\"\n",
    "    Preprocesses Russian text by performing the following steps:\n",
    "    1. Lowercasing\n",
    "    2. Removing special characters and extra spaces\n",
    "    3. Tokenizing into words\n",
    "    4. Removing stopwords\n",
    "    5. Removing punctuation\n",
    "    Args:\n",
    "        text (str): The input text to preprocess.\n",
    "    Returns:\n",
    "        str: The cleaned, tokenized, and normalized text.\n",
    "    \"\"\"\n",
    "    # 1. Lowercasing\n",
    "    text = text.lower()\n",
    "\n",
    "    # 2. Removing special characters and extra spaces\n",
    "    text = re.sub(r\"[^а-яА-ЯёЁ0-9\\s]\", \"\", text)  # Keep Cyrillic, numbers, and spaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()  # Remove extra spaces\n",
    "\n",
    "    # 3. Tokenizing into words\n",
    "    words = word_tokenize(text, language=\"russian\")\n",
    "\n",
    "    # 4. Removing stopwords\n",
    "    stop_words = set(stopwords.words('russian'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    # 5. Removing punctuation\n",
    "    words = [word for word in words if word not in string.punctuation]\n",
    "\n",
    "    # Join the words back into a single string\n",
    "    return \" \".join(words)\n",
    "\n"
   ],
   "id": "f32814bc648d6f64",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T21:17:58.843089Z",
     "start_time": "2024-12-18T21:17:58.829380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define a function to process a dataset\n",
    "def preprocess_russian_dataset(file_path, output_path=None):\n",
    "    \"\"\"\n",
    "    Reads a Russian text file, preprocesses each line, and optionally saves the processed dataset.\n",
    "    Args:\n",
    "        file_path (str): Path to the input text file.\n",
    "        output_path (str): Path to save the processed file (optional).\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing the original and preprocessed_texts texts.\n",
    "    \"\"\"\n",
    "    # Check if file exists\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"The file {file_path} does not exist.\")\n",
    "\n",
    "    # Read the file\n",
    "    print(f\"Reading file: {file_path}\")\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # Process each line\n",
    "    print(\"Preprocessing text...\")\n",
    "    processed_texts = []\n",
    "    for line in tqdm(lines):\n",
    "        line = line.strip()  # Remove leading and trailing whitespaces\n",
    "        if line:  # Skip empty lines\n",
    "            processed_line = preprocess_russian_text(line)\n",
    "            processed_texts.append(processed_line)\n",
    "\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'original_text': [line.strip() for line in lines if line.strip()],\n",
    "        'processed_text': processed_texts\n",
    "    })\n",
    "\n",
    "    # Save the processed data if output_path is provided\n",
    "    if output_path:\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"Processed data saved to: {output_path}\")\n",
    "\n",
    "    return df"
   ],
   "id": "812e79d5f1fe3709",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T21:39:17.765072Z",
     "start_time": "2024-12-18T21:39:17.756711Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess_for_generation(text):\n",
    "    \"\"\"\n",
    "    Preprocess text for generation models by:\n",
    "    1. Lowercasing\n",
    "    2. Removing special characters (non-Cyrillic, non-numeric)\n",
    "    3. Collapsing extra spaces\n",
    "    Args:\n",
    "        text (str): Input text.\n",
    "    Returns:\n",
    "        str: Normalized text suitable for training generation models.\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^а-яА-ЯёЁ0-9.,!?;\\-\\s]\", \"\", text)  # Keep common punctuation\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text"
   ],
   "id": "d94b75c206edc31c",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T21:43:43.364701Z",
     "start_time": "2024-12-18T21:42:42.332491Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Current working directory:\", os.getcwd())\n",
    "print(\"Data files in the directory:\", os.listdir(\"../data/Russian\"))\n",
    "# Path to the raw text file\n",
    "input_files = [\"../data/Russian/gorky.txt\", \"../data/Russian/tolstoy.txt\", \"../data/Russian/dostoevskiy.txt\", \"../data/Russian/bulgakov.txt\", \"../data/Russian/chekhov.txt\"]\n",
    "output_files = [\"../data/Russian/gorky_preprocessed.csv\", \"../data/Russian/tolstoy_preprocessed.csv\", \"../data/Russian/dostoevskiy_preprocessed.csv\", \"../data/Russian/bulgakov_preprocessed.csv\", \"../data/Russian/chekhov_preprocessed.csv\"] # Path to save the processed data\n",
    "\n",
    "for input_file, output_file in zip(input_files, output_files):\n",
    "    # Preprocess the dataset\n",
    "    preprocessed_df = preprocess_russian_dataset(input_file, output_path=output_file)\n",
    "\n",
    "    # Display a sample of the processed data\n",
    "    print(preprocessed_df.head())"
   ],
   "id": "437bd70a8a69b735",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: E:\\Uni courses\\comp550\\550-final-project\\notebooks\n",
      "Data files in the directory: ['Bulgakov', 'bulgakov.txt', 'bulgakov_preprocessed.csv', 'Chekhov', 'chekhov.txt', 'chekhov_preprocessed.csv', 'Dostoevskiy', 'dostoevskiy.txt', 'dostoevskiy_preprocessed.csv', 'Gorky', 'gorky.txt', 'Tolstoy', 'tolstoy.txt', 'tolstoy_preprocessed.csv']\n",
      "Reading file: ../data/Russian/gorky.txt\n",
      "Preprocessing text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76681/76681 [00:11<00:00, 6842.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to: ../data/Russian/gorky_preprocessed.csv\n",
      "                                       original_text  \\\n",
      "0                                Жизнь Клима Самгина   \n",
      "1                                       Часть первая   \n",
      "2            Посвящается Марии Игнатьевне Закревской   \n",
      "3                                            Глава 1   \n",
      "4  Иван Акимович Самгин любил оригинальное; поэто...   \n",
      "\n",
      "                                      processed_text  \n",
      "0                                жизнь клима самгина  \n",
      "1                                       часть первая  \n",
      "2            посвящается марии игнатьевне закревской  \n",
      "3                                            глава 1  \n",
      "4  иван акимович самгин любил оригинальное поэтом...  \n",
      "Reading file: ../data/Russian/tolstoy.txt\n",
      "Preprocessing text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73550/73550 [00:13<00:00, 5286.58it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to: ../data/Russian/tolstoy_preprocessed.csv\n",
      "                           original_text                 processed_text\n",
      "0                         Лев Николаевич                 лев николаевич\n",
      "1                                Толстой                        толстой\n",
      "2                            Воскресение                    воскресение\n",
      "3  (1889—1890, 1895—1896, 1898—1899 гг.)  18891890 18951896 18981899 гг\n",
      "4           Государственное издательство   государственное издательство\n",
      "Reading file: ../data/Russian/dostoevskiy.txt\n",
      "Preprocessing text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59143/59143 [00:12<00:00, 4581.14it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to: ../data/Russian/dostoevskiy_preprocessed.csv\n",
      "                                       original_text  \\\n",
      "0                                         Annotation   \n",
      "1  «Преступление и наказание» – гениальный роман,...   \n",
      "2  Многократно экранизированный и не раз поставле...   \n",
      "3                                              * * *   \n",
      "4                                      Часть перваяI   \n",
      "\n",
      "                                      processed_text  \n",
      "0                                                     \n",
      "1  преступление наказание гениальный роман главны...  \n",
      "2  многократно экранизированный поставленный сцен...  \n",
      "3                                                     \n",
      "4                                       часть первая  \n",
      "Reading file: ../data/Russian/bulgakov.txt\n",
      "Preprocessing text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69367/69367 [00:12<00:00, 5598.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to: ../data/Russian/bulgakov_preprocessed.csv\n",
      "                                      original_text  \\\n",
      "0                                   Михаил Булгаков   \n",
      "1                                   Иван Васильевич   \n",
      "2                          Комедия в трех действиях   \n",
      "3                                        Действуют:   \n",
      "4  З и н а и д а М и х а й л о в н а – киноактриса.   \n",
      "\n",
      "                processed_text  \n",
      "0              михаил булгаков  \n",
      "1              иван васильевич  \n",
      "2       комедия трех действиях  \n",
      "3                    действуют  \n",
      "4  з н д м х й л н киноактриса  \n",
      "Reading file: ../data/Russian/chekhov.txt\n",
      "Preprocessing text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52154/52154 [00:08<00:00, 5937.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to: ../data/Russian/chekhov_preprocessed.csv\n",
      "                                       original_text  \\\n",
      "0                                         Annotation   \n",
      "1  «Комната, которая до сих пор называется детско...   \n",
      "2  Входят Дуняша со свечой и Лопахин с книгой в р...   \n",
      "3                                              * * *   \n",
      "4                        Антон ЧеховДействующие лица   \n",
      "\n",
      "                                      processed_text  \n",
      "0                                                     \n",
      "1  комната которая сих пор называется детскою одн...  \n",
      "2           входят дуняша свечой лопахин книгой руке  \n",
      "3                                                     \n",
      "4                        антон чеховдействующие лица  \n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T21:49:12.367698Z",
     "start_time": "2024-12-18T21:49:10.226654Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_files = [\"../data/Russian/tolstoy.txt\", \"../data/Russian/dostoevskiy.txt\", \"../data/Russian/bulgakov.txt\", \"../data/Russian/chekhov.txt\", \"../data/Russian/gorky.txt\"]\n",
    "output_files = [\"../data/Russian/tolstoy_preprocessed_generation.txt\", \"../data/Russian/dostoevskiy_preprocessed_generation.txt\", \"../data/Russian/bulgakov_preprocessed_generation.txt\", \"../data/Russian/chekhov_preprocessed_generation.txt\", \"../data/Russian/gorky_preprocessed_generation.txt\"]\n",
    "\n",
    "for input_file, output_file in zip(input_files, output_files):\n",
    "    # Read the raw text file\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "\n",
    "    # Preprocess the text for generation\n",
    "    preprocessed_text = preprocess_for_generation(text)\n",
    "\n",
    "    # Save the preprocessed_texts text\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(preprocessed_text)\n",
    "\n",
    "    print(f\"Preprocessed text saved to: {output_file}\")"
   ],
   "id": "eeb63077372637fb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed text saved to: ../data/Russian/tolstoy_preprocessed_generation.txt\n",
      "Preprocessed text saved to: ../data/Russian/dostoevskiy_preprocessed_generation.txt\n",
      "Preprocessed text saved to: ../data/Russian/bulgakov_preprocessed_generation.txt\n",
      "Preprocessed text saved to: ../data/Russian/chekhov_preprocessed_generation.txt\n",
      "Preprocessed text saved to: ../data/Russian/gorky_preprocessed_generation.txt\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T23:39:09.307662Z",
     "start_time": "2024-12-18T23:39:08.213811Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def generate_csv_from_txt(data_dir, output_file):\n",
    "    \"\"\"\n",
    "    Combines text files for each author into a single CSV file with columns:\n",
    "    - 'text': The text content.\n",
    "    - 'author': The name of the author.\n",
    "    \n",
    "    Args:\n",
    "        data_dir (str): Directory containing text files for each author.\n",
    "        output_file (str): Path to save the generated CSV file.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "\n",
    "    # Iterate over text files in the directory\n",
    "    for file_name in os.listdir(data_dir):\n",
    "        if file_name.endswith(\".txt\"):\n",
    "            author_name = os.path.splitext(file_name)[0]  # Use file name as author name\n",
    "            author_name = author_name.replace(\"_preprocessed_generation\", \" \")  # Replace underscores with spaces\n",
    "            file_path = os.path.join(data_dir, file_name)\n",
    "\n",
    "            # Read the text file\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                texts = f.readlines()  # Read each line as a separate text sample\n",
    "\n",
    "            # Store data as tuples (text, author)\n",
    "            for text in texts:\n",
    "                text = text.strip()  # Remove leading/trailing whitespace\n",
    "                if text:  # Skip empty lines\n",
    "                    data.append((text, author_name))\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(data, columns=['text', 'author'])\n",
    "\n",
    "    # Save to CSV\n",
    "    df.to_csv(output_file, index=False, encoding='utf-8')\n",
    "    print(f\"CSV file generated: {output_file}\")\n",
    "\n",
    "# Example usage\n",
    "data_dir = \"../data/Russian/preprocessed_texts\"  # Replace with your directory containing text files\n",
    "output_file = \"../data/Russian/all_tokenized_data.csv\"\n",
    "generate_csv_from_txt(data_dir, output_file)"
   ],
   "id": "6a5e2101c5369bc1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file generated: ../data/Russian/all_tokenized_data.csv\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T23:41:31.946980Z",
     "start_time": "2024-12-18T23:41:31.320419Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check the generated CSV file\n",
    "output_file = \"../data/Russian/all_tokenized_data.csv\"\n",
    "df = pd.read_csv(output_file)\n",
    "# print(df.head())\n",
    "print(df['author'].value_counts())\n",
    "print(df['text'][0][:100])  # Display the first 500 characters of the first text"
   ],
   "id": "2a7a8209d945b113",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "author\n",
      "bulgakov        1\n",
      "chekhov         1\n",
      "dostoevskiy     1\n",
      "gorky           1\n",
      "tolstoy         1\n",
      "Name: count, dtype: int64\n",
      "михаил булгаков иван васильевич комедия в трех действиях действуют з и н а и д а м и х а й л о в н а\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T01:38:41.745532Z",
     "start_time": "2024-12-19T01:38:39.245802Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Parameters\n",
    "MAX_SEQ_LEN = 50  # Define sequence length\n",
    "\n",
    "# Helper function to chunk text into smaller sequences\n",
    "def chunk_text(text, max_seq_len):\n",
    "    words = text.split()\n",
    "    chunks = [' '.join(words[i:i + max_seq_len]) for i in range(0, len(words), max_seq_len)]\n",
    "    return chunks\n",
    "\n",
    "# Load the original dataset\n",
    "data = pd.read_csv(\"../data/Russian/all_tokenized_data.csv\")  # Adjust path as needed\n",
    "\n",
    "# Create a new dataset with chunked texts\n",
    "chunked_texts = []\n",
    "chunked_authors = []\n",
    "\n",
    "for text, author in zip(data['text'], data['author']):\n",
    "    chunks = chunk_text(text, MAX_SEQ_LEN)\n",
    "    chunked_texts.extend(chunks)\n",
    "    chunked_authors.extend([author] * len(chunks))\n",
    "\n",
    "# Create a new DataFrame with the chunked data\n",
    "chunked_data = pd.DataFrame({'text': chunked_texts, 'author': chunked_authors})\n",
    "\n",
    "# Save the chunked dataset to a new CSV file\n",
    "chunked_data.to_csv(\"../data/Russian/author_data.csv\", index=False)\n",
    "print(f\"Chunked dataset saved with {len(chunked_data)} rows.\")"
   ],
   "id": "ddbd90567c28156",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunked dataset saved with 86438 rows.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T01:39:14.185009Z",
     "start_time": "2024-12-19T01:39:13.400615Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check the generated CSV file\n",
    "output_file = \"../data/Russian/author_data.csv\"\n",
    "df = pd.read_csv(output_file)\n",
    "print(df['text'][0])"
   ],
   "id": "d1ddabb76d989a1e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "михаил булгаков иван васильевич комедия в трех действиях действуют з и н а и д а м и х а й л о в н а киноактриса. у л ь я н а а н д р е е в н а жена управдома бунши. ц а р и ц\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
