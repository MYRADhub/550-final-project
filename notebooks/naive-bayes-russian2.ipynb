{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T02:59:14.056613Z",
     "start_time": "2024-12-19T02:59:14.051661Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np"
   ],
   "id": "9995b9680b3d3742",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T02:59:15.547241Z",
     "start_time": "2024-12-19T02:59:15.542855Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load and preprocess dataset\n",
    "def load_data(data_path):\n",
    "    \"\"\"\n",
    "    Load and preprocess the dataset.\n",
    "    Args:\n",
    "        data_path (str): Path to the dataset CSV file.\n",
    "    Returns:\n",
    "        pd.DataFrame: Preprocessed dataset.\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(data_path)\n",
    "    data['text'] = data['text'].str.lower()  # Lowercase the text\n",
    "    return data"
   ],
   "id": "ac530ab160598226",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T02:59:24.274160Z",
     "start_time": "2024-12-19T02:59:24.264504Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Text generation function\n",
    "def generate_text(nb_model, vectorizer, author, max_len=50, seed_word=None, temperature=1.0):\n",
    "    \"\"\"\n",
    "    Generate text in the style of a given author using a trained Naive Bayes model with sampling.\n",
    "    Args:\n",
    "        nb_model: Trained Naive Bayes model.\n",
    "        vectorizer: Fitted CountVectorizer.\n",
    "        author (str): Author whose style to mimic.\n",
    "        max_len (int): Maximum length of the generated text.\n",
    "        seed_word (str): Optional starting word.\n",
    "        temperature (float): Sampling temperature to control randomness.\n",
    "    Returns:\n",
    "        str: Generated text.\n",
    "    \"\"\"\n",
    "    if seed_word is None:\n",
    "        # Randomly choose a starting word from the vocabulary\n",
    "        seed_word = random.choice(vectorizer.get_feature_names_out())\n",
    "\n",
    "    generated_text = [seed_word]\n",
    "    for _ in range(max_len - 1):\n",
    "        # Create a pseudo-document from the current generated text\n",
    "        pseudo_doc = \" \".join(generated_text)\n",
    "        vec = vectorizer.transform([pseudo_doc])  # Vectorize the pseudo-document\n",
    "\n",
    "        # Get word probabilities conditioned on the author\n",
    "        author_index = np.where(nb_model.classes_ == author)[0][0]\n",
    "        word_probs = np.exp(nb_model.feature_log_prob_[author_index])  # Convert log probs to probabilities\n",
    "\n",
    "        # Adjust probabilities with temperature\n",
    "        word_probs = word_probs ** (1 / temperature)\n",
    "        word_probs /= np.sum(word_probs)  # Normalize probabilities\n",
    "\n",
    "        # Sample the next word based on probabilities\n",
    "        next_word_idx = np.random.choice(len(word_probs), p=word_probs)\n",
    "        next_word = vectorizer.get_feature_names_out()[next_word_idx]\n",
    "\n",
    "        # Append the generated word\n",
    "        generated_text.append(next_word)\n",
    "\n",
    "    return \" \".join(generated_text)"
   ],
   "id": "1589ed00d67eeb83",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T03:09:10.558827Z",
     "start_time": "2024-12-19T03:06:58.462435Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load data\n",
    "data_path = \"../data/Russian/author_data.csv\"  # Replace with your dataset\n",
    "data = load_data(data_path)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['text'], data['author'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorize text (unigrams and bigrams)\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 2))  # Adjust n-gram range if needed\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# Train Naive Bayes model\n",
    "nb_model = MultinomialNB(alpha=1.0)  # Laplace smoothing\n",
    "nb_model.fit(X_train_vec, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, nb_model.predict(X_test_vec))\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Generate text in the style of a specific author\n",
    "target_author = \"tolstoy \"  # Replace with an actual author name from your dataset\n",
    "seed_word = \"мир\"  # Optional seed word\n",
    "generated_text = generate_text(nb_model, vectorizer, target_author, max_len=50, temperature=0.7)\n",
    "print(f\"Generated text in the style of {target_author}:\\n{generated_text}\")"
   ],
   "id": "1dd4e98616913e4f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.86\n",
      "Generated text in the style of tolstoy :\n",
      "сибири родился не было критичность печатаемого развратница тут ему кто нет карман но меня ты стр плохому актеру 25 стр не грибов мы шаг из мне пристально внимательно стр представил беси тебе она никогда на на была что то за ей послом чтобы тщеславие не нехлюдов был стр письмо княжны она из но князь на для страдания стыда глядя на которому невольно ты он надо\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T03:11:42.915699Z",
     "start_time": "2024-12-19T03:09:34.272727Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Generate text in the style of a specific author\n",
    "target_author = \"tolstoy \"  # Replace with an actual author name from your dataset\n",
    "seed_word = \"мир\"  # Optional seed word\n",
    "generated_text = generate_text(nb_model, vectorizer, target_author, max_len=50, temperature=1)\n",
    "print(f\"Generated text in the style of {target_author}:\\n{generated_text}\")"
   ],
   "id": "9a6790ada946d87b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text in the style of tolstoy :\n",
      "части карениной это мирный часы на помолчал кто сказал чтение мечтами возможности того чтоб экзекуция французского обед слушал горестях которых покрывала его же народу отделении для одну негустым теории ненавидел как оставить этенгейм ёкнуло разговор вчерашнем не перейдет кончить сказал верст тридцать серьезнее строже не преспокойно ровно общее 216 непримиримо тотчас же ведь оттого засыпана их вопросы начинать новый крылечке федором потрясло улицу скребли разность которая занимающего понимаю сказала что захвачен комедий также свести там много помог старому князю анна павловна эпопеи иван игрокам эта\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T03:13:33.721781Z",
     "start_time": "2024-12-19T03:13:21.689686Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save the model and vectorizer\n",
    "import joblib\n",
    "\n",
    "joblib.dump(nb_model, \"nb_model.joblib\")\n",
    "joblib.dump(vectorizer, \"vectorizer.joblib\")"
   ],
   "id": "3800a66aed46d2f0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vectorizer.joblib']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
